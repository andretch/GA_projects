{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Problem Statement](#1-Problem-Statement)  \n",
    "2. [Executive Summary](#2-Executive-Summary)  \n",
    "3. [Data Dictionary](#3-Data-Dictionary)  \n",
    "4. [Model Results](#4-Model-Results)  \n",
    "5. [Recommendations and Conclusion](#5-Recommendations-and-Conclusion)  \n",
    "6. [Future Steps](#6-Future-Steps)  \n",
    "\n",
    "\n",
    "## 1. Problem Statement\n",
    "[Return to top](#Table-of-Contents)  \n",
    "\n",
    "Our customer, a promiment auto magazine publisher has enaged us to help with accurately classifying subreddits r/cars and r/motorcycles in an effort to better understand the amout of subreddit participation between cars and motorcycles. They will use this data to position their editorials to cater to the masses.\n",
    "\n",
    "In this project, we will use the [Pushshift API](https://github.com/pushshift/api) to perform webscraping of the two abovementioned subreddits from [reddit.com](reddit.com)\n",
    "\n",
    "\n",
    "## 2. Executive Summary  \n",
    "[Return to top](#Table-of-Contents)  \n",
    "\n",
    "Following the Data Science workflow:\n",
    "- Web scraping\n",
    "- Data Cleaning  \n",
    "- Pre-Processing & Feature Engineering  \n",
    "- EDA  \n",
    "- Tokenizing  \n",
    "    - CountVectorizer  \n",
    "    - TF-IDF  \n",
    "- Modeling  \n",
    "    - Multinomial Naive Bayes Model  \n",
    "    - Random Forest Model  \n",
    "\n",
    "## 3. Data Dictionary  \n",
    "[Return to top](#Table-of-Contents)  \n",
    "\n",
    "|Feature|Type|Dataset|Description|  \n",
    "|---|---|---|---|  \n",
    "selftext | object | cars/motorcycle | text of post, 25 - 50% were labeled [Removed]  \n",
    "title | object | cars/motorcycle | title of post  \n",
    "upvote_ratio | float64 | cars/motorcycle | large portion (> 97%) 1.00   \n",
    "subreddit | object | cars/motorcycle | which subreddit the data belongs to: cars/motorcycle  \n",
    "author | object | cars/motorcycle | username  \n",
    "is_self | bool | cars/motorcycle | True / False, False indicates the lack of selftext\n",
    "\n",
    "## 4. Model Results  \n",
    "[Return to top](#Table-of-Contents)  \n",
    "TF-IDF \\| RandomForestClassifier was the worst performing with an accuracy of 0.62.  \n",
    "All other models had similar performance.  \n",
    "\n",
    "|                                           | **RESULTS** |        |          |         |\n",
    "|-------------------------------------------|-------------|--------|----------|---------|\n",
    "| Tokenizer \\| Model                        | precision   | recall | accuracy | support |\n",
    "| CountVectorizer \\| MultinomialNB          | 0.91        | 0.91   | 0.91     | 3938    |\n",
    "| TF-IDF \\| MultinomialNB                   | 0.91        | 0.91   | 0.91     | 3938    |\n",
    "| CountVectorizer \\| RandomForestClassifier | 0.91        | 0.91   | 0.91     | 3938    |\n",
    "| TF-IDF \\| RandomForestClassifier          | 0.71        | 0.62   | 0.62     | 3938    |\n",
    "\n",
    "\n",
    "## 5. Recommendations and Conclusion  \n",
    "[Return to top](#Table-of-Contents)  \n",
    "\n",
    "Since the selected tokenizer and model is able to achieve an accuracy of 91%, it significantly outdo the baseline score of 50.04%. The customer will be able to classify the posts from subreddits r/cars and r/motorcycle with a much lesser error of about 9%.\n",
    "\n",
    "With a better than baseline classification model, they will be able to better position their editorials to reach their target audience.\n",
    "\n",
    "\n",
    "## 6. Future Steps  \n",
    "[Return to top](#Table-of-Contents)  \n",
    "- trying other models such as logistic regression, K-nearest-neighbors and support vector machines to compare performance\n",
    "- expanding the data set to include a larger vocabulary and time frame\n",
    "- perform sentiment analysis to further classify the posts into good/bad sentiments \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
